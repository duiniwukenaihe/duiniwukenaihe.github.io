<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>duiniwukenaihe</title>
    <meta name="description" content="">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/page2/">
    <link rel="alternate" type="application/rss+xml" title="duiniwukenaihe" href="http://localhost:4000/feed.xml ">


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d5fc86dcc214ca5ef6e06cd0c7120d64";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>





</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/" class="brand">duiniwukenaihe</a>
        <small>SRE Engineer(target)</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>Tags
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/collection/">
                        
                            <i class="fa fa-bookmark"></i>Collections
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/demo/">
                        
                            <i class="fa fa-play"></i>Topic
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/nav/">
                        
                            <i class="fa fa-location-arrow"></i>Nav
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" index>
    <div class="left">
        <h1>Welcome to duiniwukenaihe's Blog!</h1>
        <small>这里记录着我的运维学习之路</small>
        <hr>
        <ul>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/11/26/k8s-install-new/">2019-11-26-k8s-install-new</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-11-26
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes1.16.2" title="Tag: kubernetes1.16.2" rel="tag">kubernetes1.16.2</a>&nbsp;
    
        <a href="/tag/#kuberadm" title="Tag: kuberadm" rel="tag">kuberadm</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#背景" id="markdown-toc-背景">背景</a></li>
  <li><a href="#开始" id="markdown-toc-开始">开始</a>    <ul>
      <li><a href="#首先的还是环境初始化master-work节点全部执行" id="markdown-toc-首先的还是环境初始化master-work节点全部执行">首先的还是环境初始化，master work节点全部执行</a>        <ul>
          <li><a href="#1-关闭swap" id="markdown-toc-1-关闭swap">1. 关闭swap</a></li>
          <li><a href="#2-关闭selinux" id="markdown-toc-2-关闭selinux">2. 关闭selinux</a></li>
          <li><a href="#4-开启ip转发" id="markdown-toc-4-开启ip转发">4. 开启ip转发</a></li>
          <li><a href="#5-加载ipvs" id="markdown-toc-5-加载ipvs">5. 加载ipvs</a></li>
          <li><a href="#6-journal-日志相关这里因为后面吃亏了-日志没有做切割保存查看问题太麻烦了" id="markdown-toc-6-journal-日志相关这里因为后面吃亏了-日志没有做切割保存查看问题太麻烦了">6. journal 日志相关这里因为后面吃亏了 日志没有做切割保存，查看问题太麻烦了</a></li>
          <li><a href="#7-配置yum源" id="markdown-toc-7-配置yum源">7. 配置yum源</a></li>
          <li><a href="#8-安装基本服务" id="markdown-toc-8-安装基本服务">8. 安装基本服务</a></li>
          <li><a href="#9-安装kubernetes" id="markdown-toc-9-安装kubernetes">9. 安装kubernetes</a></li>
        </ul>
      </li>
      <li><a href="#master节点操作" id="markdown-toc-master节点操作">master节点操作</a>        <ul>
          <li><a href="#1-master节点安装haproxy" id="markdown-toc-1-master节点安装haproxy">1. master节点安装haproxy</a></li>
          <li><a href="#2-kuberadm-master安装" id="markdown-toc-2-kuberadm-master安装">2. kuberadm master安装</a></li>
          <li><a href="#3-配置flannel插件" id="markdown-toc-3-配置flannel插件">3. 配置flannel插件</a></li>
          <li><a href="#4-work节点加入master" id="markdown-toc-4-work节点加入master">4. work节点加入master</a></li>
          <li><a href="#5-配置文件忘了设置ipvs了开启下ipvs这里记得在" id="markdown-toc-5-配置文件忘了设置ipvs了开启下ipvs这里记得在">5. 配置文件忘了设置ipvs了开启下ipvs.这里记得在</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>集群配置：
centos7.6</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.9</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h2 id="背景">背景</h2>

<blockquote>
  <p>前面192.168.20.13这几台机器是用kubeadm1.15 搭建过 kubernetes的，后续出现了很多问题。开始的规划很不完善，后面就重新搭建了记录下：首先说下原来的不满意的地方：</p>

  <ol>
    <li>etcd自建外部挂载，个人对etcd不是很懂，版本升级兼容问题各种解决毕竟费劲，更主要的是都上容器了，我为什么不把etcd教给容器呢？当然了存储还是挂载master主机目录的。</li>
    <li>腾讯云的slb了 还使用了haproxy，开始使用应用型负载均衡代理，后而且后面出现了各种诡异的问题，比如证书之类的。个人觉得问题应该简单化。</li>
  </ol>
</blockquote>

<blockquote>
  <p>注：https://zhangguanzhang.github.io/2019/11/24/kubeadm-base-use/很多可以参考下馆长写的文章比较详细。</p>
</blockquote>

<h2 id="开始">开始</h2>

<h3 id="首先的还是环境初始化master-work节点全部执行">首先的还是环境初始化，master work节点全部执行</h3>
<blockquote>
  <p>默认主机名已经与集群配置中对应，hostnamectl  set-hostname设置过主机名</p>
  <h4 id="1-关闭swap">1. 关闭swap</h4>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>swapoff <span class="nt">-a</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/.*swap.*/#&amp;/'</span> /etc/fstab
</code></pre></div>  </div>
  <h4 id="2-关闭selinux">2. 关闭selinux</h4>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>setenforce  0 
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^SELINUX=enforcing/SELINUX=disabled/g"</span> /etc/sysconfig/selinux 
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^SELINUX=enforcing/SELINUX=disabled/g"</span> /etc/selinux/config 
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^SELINUX=permissive/SELINUX=disabled/g"</span> /etc/sysconfig/selinux 
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^SELINUX=permissive/SELINUX=disabled/g"</span> /etc/selinux/config 
 <span class="sb">```</span>bash
<span class="c">#### 3. 调整文件打开数等配置</span>
 <span class="sb">```</span>bash
<span class="nb">echo</span> <span class="s2">"* soft nofile 65536"</span> <span class="o">&gt;&gt;</span> /etc/security/limits.conf
<span class="nb">echo</span> <span class="s2">"* hard nofile 65536"</span> <span class="o">&gt;&gt;</span> /etc/security/limits.conf
<span class="nb">echo</span> <span class="s2">"* soft nproc 65536"</span>  <span class="o">&gt;&gt;</span> /etc/security/limits.conf
<span class="nb">echo</span> <span class="s2">"* hard nproc 65536"</span>  <span class="o">&gt;&gt;</span> /etc/security/limits.conf
<span class="nb">echo</span> <span class="s2">"* soft  memlock  unlimited"</span>  <span class="o">&gt;&gt;</span> /etc/security/limits.conf
<span class="nb">echo</span> <span class="s2">"* hard memlock  unlimited"</span>  <span class="o">&gt;&gt;</span> /etc/security/limits.conf
</code></pre></div>  </div>
  <h4 id="4-开启ip转发">4. 开启ip转发</h4>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/sysctl.d/k8s.conf
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
net.ipv6.conf.lo.disable_ipv6 = 1
net.ipv4.neigh.default.gc_stale_time = 120
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
net.ipv4.conf.all.arp_announce = 2
net.ipv4.ip_forward = 1
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 1024
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 10
# 要求iptables不对bridge的数据进行处理
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-arptables = 1
net.netfilter.nf_conntrack_max = 2310720
fs.inotify.max_user_watches=89100
fs.may_detach_mounts = 1
fs.file-max = 52706963
fs.nr_open = 52706963
vm.overcommit_memory=1
vm.panic_on_oom=0
vm.swappiness = 0
</span><span class="no">EOF
</span>modprobe br_netfilter
sysctl <span class="nt">-p</span> /etc/sysctl.d/k8s.conf
sysctl <span class="nt">-p</span> /etc/sysctl.d/k8s.conf
</code></pre></div>  </div>
</blockquote>

<h4 id="5-加载ipvs">5. 加载ipvs</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/sysconfig/modules/ipvs.modules
modprobe <span class="nt">--</span> ip_vs
modprobe <span class="nt">--</span> ip_vs_rr
modprobe <span class="nt">--</span> ip_vs_wrr
modprobe <span class="nt">--</span> ip_vs_sh
modprobe <span class="nt">--</span> nf_conntrack_ipv4
<span class="nb">chmod </span>755 /etc/sysconfig/modules/ipvs.modules <span class="o">&amp;&amp;</span> bash /etc/sysconfig/modules/ipvs.modules <span class="o">&amp;&amp;</span> lsmod | <span class="nb">grep</span> <span class="nt">-e</span> ip_vs <span class="nt">-e</span> nf_conntrack_ipv4
yum <span class="nb">install </span>ipset
</code></pre></div></div>
<h4 id="6-journal-日志相关这里因为后面吃亏了-日志没有做切割保存查看问题太麻烦了">6. journal 日志相关这里因为后面吃亏了 日志没有做切割保存，查看问题太麻烦了</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sed</span> <span class="nt">-ri</span> <span class="s1">'s/^\$ModLoad imjournal/#&amp;/'</span> /etc/rsyslog.conf
<span class="nb">sed</span> <span class="nt">-ri</span> <span class="s1">'s/^\$IMJournalStateFile/#&amp;/'</span> /etc/rsyslog.conf

<span class="nb">sed</span> <span class="nt">-ri</span> <span class="s1">'s/^#(DefaultLimitCORE)=/\1=100000/'</span> /etc/systemd/system.conf
<span class="nb">sed</span> <span class="nt">-ri</span> <span class="s1">'s/^#(DefaultLimitNOFILE)=/\1=100000/'</span> /etc/systemd/system.conf

<span class="nb">sed</span> <span class="nt">-ri</span> <span class="s1">'s/^#(UseDNS )yes/\1no/'</span> /etc/ssh/sshd_config
journalctl <span class="nt">--vacuum-size</span><span class="o">=</span>20M
</code></pre></div></div>
<h4 id="7-配置yum源">7. 配置yum源</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yum-config-manager <span class="nt">--add-repo</span> http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg 
</span><span class="no">EOF
</span></code></pre></div></div>
<h4 id="8-安装基本服务">8. 安装基本服务</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>安装依赖包
yum <span class="nb">install</span> <span class="nt">-y</span> epel-release
yum <span class="nb">install</span> <span class="nt">-y</span> yum-utils device-mapper-persistent-data lvm2 net-tools conntrack-tools wget vim  ntpdate libseccomp libtool-ltdl
安装bash命令提示
yum <span class="nb">install</span> <span class="nt">-y</span> bash-argsparse bash-completion bash-#completion-extras
安装docker kubeadm:
yum <span class="nb">install </span>docker-ce <span class="nt">-y</span>
<span class="c">#配置镜像加速器 </span>
<span class="nb">sudo mkdir</span> <span class="nt">-p</span> /etc/docker
<span class="nb">sudo tee</span> /etc/docker/daemon.json <span class="o">&lt;&lt;-</span><span class="sh">'</span><span class="no">EOF</span><span class="sh">'
{
  "registry-mirrors": ["https://lrpol8ec.mirror.aliyuncs.com"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
}
}
</span><span class="no">EOF
</span><span class="nb">sudo </span>systemctl daemon-reload
<span class="nb">sudo </span>systemctl restart docker
添加个日志最多值，否则有的苦了，入坑体验过了。docker要不要开机启动呢？我后面安装rook ceph 开机重新启动了老有错误，因为没有将节点设置为cordon，但是也懒了， 我就没有设置为开机启动。故开机启动后在启动docker了
</code></pre></div></div>
<h4 id="9-安装kubernetes">9. 安装kubernetes</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yum <span class="nb">install</span> <span class="nt">-y</span> kubelet kubeadm kubectl <span class="nt">--disableexcludes</span><span class="o">=</span>kubernetes
systemctl <span class="nb">enable </span>kubelet
</code></pre></div></div>

<h3 id="master节点操作">master节点操作</h3>
<h4 id="1-master节点安装haproxy">1. master节点安装haproxy</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yum <span class="nb">install</span> <span class="nt">-y</span> haproxy
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/haproxy/haproxy.cfg

#---------------------------------------------------------------------
# Example configuration for a possible web application.  See the
# full configuration options online.
#
#   http://haproxy.1wt.eu/download/1.4/doc/configuration.txt
#
#---------------------------------------------------------------------

#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    # to have these messages end up in /var/log/haproxy.log you will
    # need to:
    #
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the '-r' option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    #
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local2

    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon

    # turn on stats unix socket
    stats socket /var/lib/haproxy/stats

#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#---------------------------------------------------------------------
defaults
    mode                    tcp
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 3000

#---------------------------------------------------------------------
# main frontend which proxys to the backends
#---------------------------------------------------------------------
frontend kubernetes
    bind *:8443              #配置端口为8443
    mode tcp
    default_backend kubernetes-master
#---------------------------------------------------------------------
# static backend for serving up images, stylesheets and such
#---------------------------------------------------------------------
backend kubernetes-master           #后端服务器，也就是说访问192.168.255.140:8443会将请求转发到后端的三台，这样就实现了负载均衡
    balance roundrobin               
    server master1  192.168.3.10:6443 check maxconn 2000
    server master2  192.168.3.5:6443 check maxconn 2000
    server master3  192.168.3.12:6443 check maxconn 2000
</span><span class="no">EOF
</span> systemctl <span class="nb">enable </span>haproxy <span class="o">&amp;&amp;</span> systemctl start haproxy <span class="o">&amp;&amp;</span> systemctl status haproxy

腾讯云slb负载均衡最终还是用了传统型，监听器tcp 6443代理后端三台haproxy 8443端口
</code></pre></div></div>
<h4 id="2-kuberadm-master安装">2. kuberadm master安装</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>master1节点
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.16.2
apiServer:
  certSANs:
    - k8s-master-01
    - k8s-master-02
    - k8s-master-03
    - k8s-master-04
    - master.k8s.io
    - 192.168.3.10
    - 192.168.3.5
    - 192.168.3.12
    - 192.168.3.9
    - 192.168.3.3
    - 127.0.0.1
controlPlaneEndpoint: "192.168.3.9:6443"
controllerManager: {}
dns: 
  type: CoreDNS
etcd:
    local:
      dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers
networking:
  podSubnet: 10.30.0.0/16
  serviceSubnet: 10.31.0.0/16
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> kubeadm-config.yaml
现在最新的是1.16.3，安装的时候是1.16.2就用了默认配置文件了。网络规划不会弄，这样貌似有点很差劲，因为以后想弄联邦集群，后面再想解决方法吧。另外腾讯云曾经开源过一个tencentcloud-cloud-controller-manager，其实很多可以打通的，但是试用了下 坑多的样子没有跑通，放弃了
kubeadm init <span class="nt">--config</span> initconfig.yaml
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$HOME</span>/.kube
<span class="nb">sudo</span> <span class="se">\c</span>p /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
<span class="nb">sudo chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> <span class="nv">$HOME</span>/.kube/config

按照输出master02 ，master03节点加入集群
 kubeadm <span class="nb">join </span>192.168.3.9:6443 <span class="nt">--token</span> jiprvz.0rkovt1gx3d658j     <span class="nt">--discovery-token-ca-cert-hash</span> sha256:5d631bb4bdce033163037ef21f663c88e058e70c6c362c9c5ccb1a92095     <span class="nt">--control-plane</span> <span class="nt">--certificate-key</span> 0eaa7e5f8efbdc8d381fb329c28c49f87af284fecc0c9443501e81f3cdc4
将master01 /etc/kubernetes/pki目录下ca<span class="k">*</span> sa<span class="k">*</span> fr<span class="k">*</span> etcd 打包分发到master02,master03 /etc/kubernetes/pki目录下 
注： key都胡乱输入的这里没有用自己的，复制pki这部忘了 老的版本都复制来，记得这个版本我没有复制key的？可以安装流程自己看看
</code></pre></div></div>
<h4 id="3-配置flannel插件">3. 配置flannel插件</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
修改配置文件中Network 为自己设置的子网，我这里是10.30.0.0/16
kubectl apply <span class="nt">-f</span> kube-flannel.yml
然后基本发现 master节点都已经redeay
</code></pre></div></div>
<h4 id="4-work节点加入master">4. work节点加入master</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubeadm <span class="nb">join </span>192.168.3.9:6443 <span class="nt">--token</span> 3o6dy0.9gbbfuf55xiloe9d <span class="nt">--discovery-token-ca-cert-hash</span> sha256:5d631bb4bdce01dcad51163037ef21f663c88e058e70c6c362c9c5ccb1a92095
OK集群算是初始搭建完了，不知道跑一遍咋样，我的是正常跑起来了。
</code></pre></div></div>
<h4 id="5-配置文件忘了设置ipvs了开启下ipvs这里记得在">5. 配置文件忘了设置ipvs了开启下ipvs.这里记得在</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl edit cm kube-proxy <span class="nt">-n</span> kube-system
configmap/kube-proxy edited

<span class="c">#修改如下</span>
kind: MasterConfiguration
apiVersion: kubeadm.k8s.io/v1alpha1
...
ipvs:
      excludeCIDRs: null
      minSyncPeriod: 0s
      scheduler: <span class="s2">""</span>
      syncPeriod: 30s
    kind: KubeProxyConfiguration
    metricsBindAddress: 127.0.0.1:10249
    mode: <span class="s2">"ipvs"</span>                  <span class="c">#修改</span>

kubectl get pod <span class="nt">-n</span> kube-system | <span class="nb">grep </span>kube-proxy |awk <span class="s1">'{system("kubectl delete pod "$1" -n kube-system")}'</span>
</code></pre></div></div>
<blockquote>
  <p>貌似应该就跑起来了，然后后面应该还要做的：</p>
  <ol>
    <li>etcd的备份，虽然有三个master节点 数据无价，还是做下etcd的备份要好。</li>
    <li>pods 可能都running了 但是最后还是看下日志，肯能有些小的失误，看日志是个好习惯的，老版本糊里糊涂搭建的时候kubernetes插件pod打了一大堆日志 虽然可以使用，但是还是要追求下完美的。由此可见搭建日志采集系统还是很有必要的。</li>
    <li>work节点最好打上标签，不是服务设置亲和性和反亲和性。资源的调度使用值貌似可以设置的？否则后面有的work会出现pods一直创建中，打标签合理规划资源还是很有必要的。</li>
  </ol>
</blockquote>

                </div>
                <div class="read-all">
                    <a  href="/2019/11/26/k8s-install-new/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/11/25/k8s-question2/">2019-11-25-k8s-question2</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-11-25
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#question" title="Tag: question" rel="tag">question</a>&nbsp;
    
        <a href="/tag/#no" title="Tag: no" rel="tag">no</a>&nbsp;
    
        <a href="/tag/#space" title="Tag: space" rel="tag">space</a>&nbsp;
    
        <a href="/tag/#left" title="Tag: left" rel="tag">left</a>&nbsp;
    
        <a href="/tag/#on" title="Tag: on" rel="tag">on</a>&nbsp;
    
        <a href="/tag/#device" title="Tag: device" rel="tag">device</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#创建-pod-失败describe-pod-看-event-报-no-space-left-on-device集群运行120天左右出现" id="markdown-toc-创建-pod-失败describe-pod-看-event-报-no-space-left-on-device集群运行120天左右出现">创建 Pod 失败，describe pod 看 event 报 no space left on device.集群运行120天左右出现。</a></li>
  <li><a href="#prune命令的使用" id="markdown-toc-prune命令的使用">prune命令的使用：</a>    <ul>
      <li><a href="#1-prune-images" id="markdown-toc-1-prune-images">1. Prune Images</a></li>
      <li><a href="#2-prune-containers" id="markdown-toc-2-prune-containers">2. Prune containers</a></li>
      <li><a href="#3-prune-volumes" id="markdown-toc-3-prune-volumes">3. prune volumes</a></li>
      <li><a href="#4-prune-networks" id="markdown-toc-4-prune-networks">4. prune networks</a></li>
      <li><a href="#5-prune-everything" id="markdown-toc-5-prune-everything">5. prune everything</a></li>
    </ul>
  </li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：记录各种常见问题</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="创建-pod-失败describe-pod-看-event-报-no-space-left-on-device集群运行120天左右出现">创建 Pod 失败，describe pod 看 event 报 no space left on device.集群运行120天左右出现。</h1>
<blockquote>
  <p>可参照https://www.bookstack.cn/read/kubernetes-practice-guide/troubleshooting-problems-errors-no-space-left-on-device.md。出现此问题cgroup泄露问题。最笨方法可以用reboot下，或者删除节点重新添加下。瞄了一眼/var/lib/docker/overlay2 下文件有快70G，/var/log/journal/日志也有4-5G。</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl <span class="nt">--vacuum-size</span><span class="o">=</span>20M
设置journal 日志最大为20M不保留不必要日志。
</code></pre></div></div>
<h1 id="prune命令的使用">prune命令的使用：</h1>
<blockquote>
  <p>看了下文档与资料，对于不再使用的镜像容器，存储以及网络资源 docker采取的是被动清理方式。所以自然而然的，默认文件夹下文件会越来越大。docker 也为此提供了prune的命令。</p>
</blockquote>

<h2 id="1-prune-images">1. Prune Images</h2>
<blockquote>
  <p>docker image prune 可以用来清理不再使用的docker镜像。执行docker image prune默认会清除”悬空”镜像。“悬空”镜像，就是既没有标签名也没有容器引用的镜像就叫”悬空”镜像。具体操作如下：</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker image prune
WARNING! This will remove all dangling images.
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
想要清除所有没有容器引用的镜像，增加一个 <span class="nt">-a</span> 标志就可以搞定：
<span class="nv">$ </span>docker image prune <span class="nt">-a</span>
WARNING! This will remove all images without at least one container associated to them.
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
清除操作会提醒你是否真心想要清除对象，默认是选项会是yes；但是如果你嫌提示麻烦，可以通过-f 或者--force标志来进行强制清除。
更加人性化的是，Docker提供了--filter标志筛选出想要保留的镜像。例如：只清除超过创建时间超过24小时的镜像可以这样来操作：
<span class="nv">$ </span>docker image prune <span class="nt">-a</span> <span class="nt">--filter</span> <span class="s2">"until=24h"</span>
 当然还能够通过其他的表达式来定制我的镜像清理计划。更多的示例参考docker image prune.
</code></pre></div></div>
<h2 id="2-prune-containers">2. Prune containers</h2>
<blockquote>
  <p>容器启动时没有指定–rm选项，容器停止时是不能够自动清除的。有时候我们无所事事的敲下docker ps -a命令会惊奇的发现，天哪，居然有这么多容器，有运行着的也有停止了的。它们是哪里来的？它们到底还有没有人在关注？这种情况在一个开发环境上尤其常见。即使容器已经停掉了也会占用空间资源。这个时候可以使用docker container prune命令:</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker container prune
WARNING! This will remove all stopped containers.
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] 
和镜像清理的情况一样，也会有提示信息告诉你是否继续，默认是yes；如果提示信息烦到了你的话就加上 <span class="nt">-f</span> 或者 <span class="nt">--force</span>标志强制清除就可以了。
默认情况下docker container prune命令会清理掉所有处于stopped状态的容器；如果不想那么残忍统统都删掉，也可以使用--filter标志来筛选出不希望被清理掉的容器。下面是一个筛选的例子，清除掉所有停掉的容器，但24内创建的除外：
<span class="nv">$ </span>docker container prune <span class="nt">--filter</span> <span class="s2">"until=24h"</span>
其他的筛选条件的实现可以参考：docker container prune reference， 这里有更多的详细的例子。
</code></pre></div></div>

<h2 id="3-prune-volumes">3. prune volumes</h2>

<blockquote>
  <p>Volumes可被一个或多个容器使用会消耗host端的空间，但它不会自动清理，因为那样就有可能破坏掉有用的数据。</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker volume prune
WARNING! This will remove all volumes not used by at least one container.
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
和conatiner一样，手动清理Volume时会有提示信息，增加-f 或--force标志可以跳过提示信息直接清理。使用过滤参数--filter来筛选出不希望清理的无用Volume，否则默认会将所有没有使用的volumes都清理掉。下面的例子演示了除lable<span class="o">=</span>keep外的volume外都清理掉<span class="o">(</span>没有引用的volume<span class="o">)</span>：
<span class="nv">$ </span>docker volume prune <span class="nt">--filter</span> <span class="s2">"label!=keep"</span>
其他的筛选条件的实现可以参考：docker volume prune reference，这里给出了更多参考示例。
</code></pre></div></div>

<h2 id="4-prune-networks">4. prune networks</h2>

<blockquote>
  <p>虽然Docker networks占用的空间不多，但是它会创建iptable 规则、虚拟网桥设备以及路由表项，有洁癖的你看到这么多”僵尸”对象会不会抓狂？当然，我们还是要用清理神器：docker network prune 来清理没有再被任何容器引用的networks：</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker network prune
 
WARNING! This will remove all networks not used by at least one container.
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
 可以通过 <span class="nt">-f</span> 或者 <span class="nt">--force</span>标志跳过提示信息来强制执行该命令。默认情况会清除所有没有再被引用的networks，如果想要过滤一些特定的networks，可以使用--filter来实现。下面这个例子就是通过--filter来清理没有被引用的、创建超过24小时的networks：
<span class="nv">$ </span>docker network prune <span class="nt">--filter</span> <span class="s2">"until=24h"</span>
更多关于docker network的--filter的筛选条件可参考示例：docker network prune reference 。
</code></pre></div></div>

<h2 id="5-prune-everything">5. prune everything</h2>
<blockquote>
  <p>如题，这里要讲的就是清理everything：images ，containers，networks一次性清理操作可以通过docker system prune来搞定。在Docker 17.06.0 以及更早的版本中，这个docker system prune也会将volume一起清理掉；在Docker 17.06.1以及后期的版本中则必须要手动指定–volumes标志才能够清理掉volumes：</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker system prune
 
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
在Docker 17.06.1或更高版本中添加--volumes标志的情况：
<span class="nv">$ </span>docker system prune <span class="nt">--volumes</span>
 
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all volumes not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
貌似删除很有限，我的只删除了几百m
docker system prune <span class="nt">-a</span> 
WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all volumes not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to <span class="k">continue</span>? <span class="o">[</span>y/N] y
这样管用些删除了 12G空间
</code></pre></div></div>
<p><img src="/assets/images/qustion/prune.png" alt="prune.png" />
<img src="/assets/images/qustion/prune1.png" alt="prune1.png" />
<img src="/assets/images/qustion/prune2.png" alt="prune2.png" /></p>


                </div>
                <div class="read-all">
                    <a  href="/2019/11/25/k8s-question2/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/11/19/cncf-ali/">k8s-install-jenkins</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-11-19
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes1.16" title="Tag: kubernetes1.16" rel="tag">kubernetes1.16</a>&nbsp;
    
        <a href="/tag/#jenkins" title="Tag: jenkins" rel="tag">jenkins</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#安装jenkins" id="markdown-toc-安装jenkins">安装jenkins</a>    <ul>
      <li><a href="#登陆jenkins初始化配置" id="markdown-toc-登陆jenkins初始化配置">登陆jenkins。初始化配置</a></li>
    </ul>
  </li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：kubernetes基本环境搭建完成，存储rook-ceph，rbd方式。代码仓库gitlab,容器仓库harbor,监控prometheus，负载方式都用了内部clusterip然后 traefik代理的方式。为了完善工具链，容器中搭建jenkins工具。</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="安装jenkins">安装jenkins</h1>
<blockquote>
  <ol>
    <li>建立命名空间
      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create namespace kube-ops
注：后续所有工具类应用程序都创建在此命名空间内。
</code></pre></div>      </div>
      <hr />
    </li>
    <li>创建ServiceAccount &amp; ClusterRoleBinding</li>
  </ol>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>注：都是用的默认的，权限的管理还没有深入进行学习下。

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; rabc.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins2
  namespace: kube-ops
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: jenkins2
rules:
  - apiGroups: ["extensions", "apps"]
    resources: ["deployments"]
    verbs: ["create", "delete", "get", "list", "watch", "patch", "update"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["create", "delete", "get", "list", "watch", "patch", "update"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["create","delete","get","list","patch","update","watch"]
  - apiGroups: [""]
    resources: ["pods/exec"]
    verbs: ["create","delete","get","list","patch","update","watch"]
  - apiGroups: [""]
    resources: ["pods/log"]
    verbs: ["get","list","watch"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: jenkins2
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: jenkins2
subjects:
  - kind: ServiceAccount
    name: jenkins2
    namespace: kube-ops
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> rabc.yaml
</code></pre></div></div>

<blockquote>
  <p>3.deployment jenkins</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; jenkins.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: opspvc
  labels:
    app: jenkins2
  namespace: kube-ops
spec:
  storageClassName: rook-ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jenkins2
  namespace: kube-ops
spec:
  selector:
    matchLabels:
      app: jenkins2
  template:
    metadata:
      labels:
        app: jenkins2
    spec:
      terminationGracePeriodSeconds: 10
      serviceAccountName: jenkins2
      containers:
      - name: jenkins
        image: jenkins/jenkins:lts
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: web
          protocol: TCP
        - containerPort: 50000
          name: agent
          protocol: TCP
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        readinessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        volumeMounts:
        - name: jenkinshome
          subPath: jenkins2
          mountPath: /var/jenkins_home
        env:
        - name: LIMITS_MEMORY
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
              divisor: 1Mi
        - name: JAVA_OPTS
          value: -Xmx</span><span class="si">$(</span>LIMITS_MEMORY<span class="si">)</span><span class="sh">m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai
      securityContext:
        fsGroup: 1000
      volumes:
      - name: jenkinshome
        persistentVolumeClaim:
          claimName: opspvc

---
apiVersion: v1
kind: Service
metadata:
  name: jenkins2
  namespace: kube-ops
  labels:
    app: jenkins2
spec:
  selector:
    app: jenkins2
  ports:
  - name: web
    port: 8080
    targetPort: web
  - name: agent
    port: 50000
    targetPort: agent
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> jenkins.yaml
注： kubernetes 1.16 取消了extensions/v1beta1 api，使用apps/v1。
</code></pre></div></div>
<p><img src="/assets/images/jenkins/deployment.png" alt="deployment.png" /></p>
<blockquote>
  <p>4.traefik对外暴露服务</p>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; ingress.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: jenkins2-https
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(</span><span class="se">\`</span><span class="sh">jenkins.sainaihe.com</span><span class="se">\`</span><span class="sh">)
      kind: Rule
      services:
        - name: jenkins2
          port: 8080
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> ingress.yaml
</code></pre></div>  </div>
  <p><img src="/assets/images/jenkins/ingressroute.png" alt="ingressroute.png" />
<img src="/assets/images/jenkins/traefik.png" alt="traefik.png" /></p>
  <h2 id="登陆jenkins初始化配置">登陆jenkins。初始化配置</h2>
  <ol>
    <li>访问 https://jenkins.saynaihe.com,出现：
<img src="/assets/images/jenkins/jenkins1.png" alt="jenkins1.png" />
获取初始密码
      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nb">exec</span> <span class="nt">-it</span> jenkins2-9f55b98b6-xtffb <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword <span class="nt">-n</span> kube-ops
</code></pre></div>      </div>
      <p><img src="/assets/images/jenkins/jenkins2.png" alt="jenkins2.png" /></p>
    </li>
    <li>设置管理员账号密码，进入登陆界面
<img src="/assets/images/jenkins/jenkins3.png" alt="jenkins3.png" /></li>
    <li>安装插件，安装了中文插件，pipeline，gitlab,git,github 参数化插件等，看个人需要安装吧。
<img src="/assets/images/jenkins/jenkins4.png" alt="jenkins4.png" />
<img src="/assets/images/jenkins/jenkins5.png" alt="jenkins5.png" />
注：因为国外源不稳定 国内有其他备用源可以切换比如清华的源。jenkins中文社区有篇文章：https://mp.weixin.qq.com/s/rqx93WI0UEvzqaFrt84i8A可以参考。</li>
  </ol>
</blockquote>

                </div>
                <div class="read-all">
                    <a  href="/2019/11/19/cncf-ali/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/11/19/k8s-install-jenkins/">k8s-install-jenkins</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-11-19
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes1.16" title="Tag: kubernetes1.16" rel="tag">kubernetes1.16</a>&nbsp;
    
        <a href="/tag/#jenkins" title="Tag: jenkins" rel="tag">jenkins</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#安装jenkins" id="markdown-toc-安装jenkins">安装jenkins</a>    <ul>
      <li><a href="#登陆jenkins初始化配置" id="markdown-toc-登陆jenkins初始化配置">登陆jenkins。初始化配置</a></li>
    </ul>
  </li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：kubernetes基本环境搭建完成，存储rook-ceph，rbd方式。代码仓库gitlab,容器仓库harbor,监控prometheus，负载方式都用了内部clusterip然后 traefik代理的方式。为了完善工具链，容器中搭建jenkins工具。</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="安装jenkins">安装jenkins</h1>
<blockquote>
  <ol>
    <li>建立命名空间
      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create namespace kube-ops
注：后续所有工具类应用程序都创建在此命名空间内。
</code></pre></div>      </div>
      <hr />
    </li>
    <li>创建ServiceAccount &amp; ClusterRoleBinding</li>
  </ol>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>注：都是用的默认的，权限的管理还没有深入进行学习下。

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; rabc.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins2
  namespace: kube-ops
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: jenkins2
rules:
  - apiGroups: ["extensions", "apps"]
    resources: ["deployments"]
    verbs: ["create", "delete", "get", "list", "watch", "patch", "update"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["create", "delete", "get", "list", "watch", "patch", "update"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["create","delete","get","list","patch","update","watch"]
  - apiGroups: [""]
    resources: ["pods/exec"]
    verbs: ["create","delete","get","list","patch","update","watch"]
  - apiGroups: [""]
    resources: ["pods/log"]
    verbs: ["get","list","watch"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: jenkins2
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: jenkins2
subjects:
  - kind: ServiceAccount
    name: jenkins2
    namespace: kube-ops
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> rabc.yaml
</code></pre></div></div>

<blockquote>
  <p>3.deployment jenkins</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; jenkins.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: opspvc
  labels:
    app: jenkins2
  namespace: kube-ops
spec:
  storageClassName: rook-ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jenkins2
  namespace: kube-ops
spec:
  selector:
    matchLabels:
      app: jenkins2
  template:
    metadata:
      labels:
        app: jenkins2
    spec:
      terminationGracePeriodSeconds: 10
      serviceAccountName: jenkins2
      containers:
      - name: jenkins
        image: jenkins/jenkins:lts
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: web
          protocol: TCP
        - containerPort: 50000
          name: agent
          protocol: TCP
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        readinessProbe:
          httpGet:
            path: /login
            port: 8080
          initialDelaySeconds: 60
          timeoutSeconds: 5
          failureThreshold: 12
        volumeMounts:
        - name: jenkinshome
          subPath: jenkins2
          mountPath: /var/jenkins_home
        env:
        - name: LIMITS_MEMORY
          valueFrom:
            resourceFieldRef:
              resource: limits.memory
              divisor: 1Mi
        - name: JAVA_OPTS
          value: -Xmx</span><span class="si">$(</span>LIMITS_MEMORY<span class="si">)</span><span class="sh">m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai
      securityContext:
        fsGroup: 1000
      volumes:
      - name: jenkinshome
        persistentVolumeClaim:
          claimName: opspvc

---
apiVersion: v1
kind: Service
metadata:
  name: jenkins2
  namespace: kube-ops
  labels:
    app: jenkins2
spec:
  selector:
    app: jenkins2
  ports:
  - name: web
    port: 8080
    targetPort: web
  - name: agent
    port: 50000
    targetPort: agent
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> jenkins.yaml
注： kubernetes 1.16 取消了extensions/v1beta1 api，使用apps/v1。
</code></pre></div></div>
<p><img src="/assets/images/jenkins/deployment.png" alt="deployment.png" /></p>
<blockquote>
  <p>4.traefik对外暴露服务</p>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; ingress.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: jenkins2-https
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(</span><span class="se">\`</span><span class="sh">jenkins.sainaihe.com</span><span class="se">\`</span><span class="sh">)
      kind: Rule
      services:
        - name: jenkins2
          port: 8080
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> ingress.yaml
</code></pre></div>  </div>
  <p><img src="/assets/images/jenkins/ingressroute.png" alt="ingressroute.png" />
<img src="/assets/images/jenkins/traefik.png" alt="traefik.png" /></p>
  <h2 id="登陆jenkins初始化配置">登陆jenkins。初始化配置</h2>
  <ol>
    <li>访问 https://jenkins.saynaihe.com,出现：
<img src="/assets/images/jenkins/jenkins1.png" alt="jenkins1.png" />
获取初始密码
      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nb">exec</span> <span class="nt">-it</span> jenkins2-9f55b98b6-xtffb <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword <span class="nt">-n</span> kube-ops
</code></pre></div>      </div>
      <p><img src="/assets/images/jenkins/jenkins2.png" alt="jenkins2.png" /></p>
    </li>
    <li>设置管理员账号密码，进入登陆界面
<img src="/assets/images/jenkins/jenkins3.png" alt="jenkins3.png" /></li>
    <li>安装插件，安装了中文插件，pipeline，gitlab,git,github 参数化插件等，看个人需要安装吧。
<img src="/assets/images/jenkins/jenkins4.png" alt="jenkins4.png" />
<img src="/assets/images/jenkins/jenkins5.png" alt="jenkins5.png" />
注：因为国外源不稳定 国内有其他备用源可以切换比如清华的源。jenkins中文社区有篇文章：https://mp.weixin.qq.com/s/rqx93WI0UEvzqaFrt84i8A可以参考。</li>
  </ol>
</blockquote>

                </div>
                <div class="read-all">
                    <a  href="/2019/11/19/k8s-install-jenkins/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/11/05/k8s-install-prometheus-operator/">k8s-install-prometheus-operator</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-11-05
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>&nbsp;
    
        <a href="/tag/#prometheus-operator" title="Tag: prometheus-operator" rel="tag">prometheus-operator</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a>    <ul>
      <li><a href="#安装prometheus-operator" id="markdown-toc-安装prometheus-operator">安装prometheus-operator</a>        <ul>
          <li><a href="#克隆prometheus-operator仓库" id="markdown-toc-克隆prometheus-operator仓库">克隆prometheus-operator仓库</a></li>
        </ul>
      </li>
      <li><a href="#treafik代理prometheus-grafana-alertmanager" id="markdown-toc-treafik代理prometheus-grafana-alertmanager">treafik代理prometheus grafana alertmanager</a></li>
      <li><a href="#添加-kubecontrollermanager-kubescheduler监控" id="markdown-toc-添加-kubecontrollermanager-kubescheduler监控">添加 kubeControllerManager kubeScheduler监控</a></li>
      <li><a href="#监控集群etcd服务" id="markdown-toc-监控集群etcd服务">监控集群etcd服务</a>        <ul>
          <li><a href="#kubadm安装集成etcd方式下操作" id="markdown-toc-kubadm安装集成etcd方式下操作">kubadm安装集成etcd方式下操作：</a></li>
          <li><a href="#kubadm安装挂载外部安装etcd方式下操作" id="markdown-toc-kubadm安装挂载外部安装etcd方式下操作">kubadm安装挂载外部安装etcd方式下操作：</a></li>
        </ul>
      </li>
      <li><a href="#开启服务自动发现配置可持续存储修改prometheus-storage-retention参数设置数据保留时间" id="markdown-toc-开启服务自动发现配置可持续存储修改prometheus-storage-retention参数设置数据保留时间">开启服务自动发现，配置可持续存储，修改prometheus Storage Retention参数设置数据保留时间</a>        <ul>
          <li><a href="#由于rabc权限问题prometheus-dashboard-的配置页面下面我们可以看到已经有了对应的的配置信息了但是我们切换到-targets-页面下面却并没有发现对应的监控任务" id="markdown-toc-由于rabc权限问题prometheus-dashboard-的配置页面下面我们可以看到已经有了对应的的配置信息了但是我们切换到-targets-页面下面却并没有发现对应的监控任务">由于RABC权限问题，Prometheus Dashboard 的配置页面下面我们可以看到已经有了对应的的配置信息了，但是我们切换到 targets 页面下面却并没有发现对应的监控任务</a></li>
        </ul>
      </li>
      <li><a href="#grafana添加监控模板持久化" id="markdown-toc-grafana添加监控模板持久化">grafana添加监控模板，持久化</a>        <ul>
          <li><a href="#持久化" id="markdown-toc-持久化">持久化</a></li>
          <li><a href="#grafana添加模板只添加了treafik2-和etcd模板" id="markdown-toc-grafana添加模板只添加了treafik2-和etcd模板">grafana添加模板，只添加了treafik2 和etcd模板</a></li>
        </ul>
      </li>
      <li><a href="#微信报警" id="markdown-toc-微信报警">微信报警</a></li>
    </ul>
  </li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：搭建prometheus-operator</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h2 id="安装prometheus-operator">安装prometheus-operator</h2>

<blockquote>

  <p>先说下自己的流程：</p>
  <ol>
    <li>克隆prometheus-operator仓库</li>
    <li>按照官方quickstart进行安装</li>
    <li>treafik代理prometheus grafana alertmanager</li>
    <li>添加 kubeControllerManager kubeScheduler监控</li>
    <li>监控集群etcd服务</li>
    <li>开启服务自动发现，配置可持续存储，修改prometheus Storage Retention参数设置数据保留时间</li>
    <li>grafana添加监控模板，持久化</li>
    <li>微信报警</li>
  </ol>
</blockquote>

<h3 id="克隆prometheus-operator仓库">克隆prometheus-operator仓库</h3>

<blockquote>
  <p>注：新版本升级后和旧版本文件结构有些不一样 可以参照github仓库文档quickstart.</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/coreos/kube-prometheus
<span class="nb">cd </span>kube-prometheus
<span class="c">###创建命名空间和crd.保证可用后建立相关资源</span>
kubectl create <span class="nt">-f</span> manifests/setup
<span class="k">until </span>kubectl get servicemonitors <span class="nt">--all-namespaces</span> <span class="p">;</span> <span class="k">do </span><span class="nb">date</span><span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="nb">echo</span> <span class="s2">""</span><span class="p">;</span> <span class="k">done
</span>kubectl create <span class="nt">-f</span> manifests/
kubectl get pods <span class="nt">-n</span> monitoring
<span class="o">[</span>root@k8s-master-01 work]# kubectl get pods <span class="nt">-n</span> monitoring
NAME                                  READY   STATUS             RESTARTS   AGE
grafana-58dc7468d7-6v86k              1/1     Running            0          9m
kube-state-metrics-78b46c84d8-ns7hk   2/3     ImagePullBackOff   0          9m
node-exporter-4pr77                   2/2     Running            0          9m
node-exporter-6jhz5                   2/2     Running            0          9m
node-exporter-8xv8v                   2/2     Running            0          9m
node-exporter-ngt9r                   2/2     Running            0          9m
node-exporter-nlff4                   2/2     Running            0          9m
node-exporter-pw554                   2/2     Running            0          9m
node-exporter-rwpfj                   2/2     Running            0          9m
node-exporter-thz4j                   2/2     Running            0          9m
prometheus-adapter-5cd5798d96-2jnjl   0/1     ImagePullBackOff   0          9m
prometheus-operator-99dccdc56-zr6fw   0/1     ImagePullBackOff   0          9m11s
</code></pre></div></div>
<blockquote>
  <p>注意：会出现有些镜像下载不下来的问题，可墙外服务器下载镜像修改tag上传到harbor，修改yaml文件中镜像为对应harbor tag解决。最终如下图：
<img src="/assets/images/monitoring/create.png" alt="create.png" /> 
<img src="/assets/images/monitoring/status.png" alt="state.png" /></p>
</blockquote>

<h2 id="treafik代理prometheus-grafana-alertmanager">treafik代理prometheus grafana alertmanager</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitoring下创建http证书<span class="o">(</span>ssl证书目录下执行<span class="o">)</span>
kubectl create secret tls all-saynaihe-com <span class="nt">--key</span><span class="o">=</span>2_sainaihe.com.key <span class="nt">--cert</span><span class="o">=</span>1_saynaihe.com_bundle.crt <span class="nt">-n</span> monitoring

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; monitoring.com.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: monitoring
  name: alertmanager-main-https
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`alertmanager.saynaihe.com`)
      kind: Rule
      services:
        - name: alertmanager-main
          port: 9093
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: monitoring
  name: grafana-https
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`monitoring.saynaihe.com`)
      kind: Rule
      services:
        - name: grafana
          port: 3000
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: monitoring
  name: prometheus
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`prometheus.saynaihe.com`)
      kind: Rule
      services:
        - name: prometheus-k8s
          port: 9090
---
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> monitoring.com.yaml
登录https://monitoring.saynaihe.com/ 
https://prometheus.saynaihe.com/
https://alertmanager.saynaihe.com/
查看,如下图：
</code></pre></div></div>
<p><img src="/assets/images/monitoring/grafana.png" alt="grafana.png" />
<img src="/assets/images/monitoring/prometheus.png" alt="prometheus.png" /> 
<img src="/assets/images/monitoring/alertmanager.png" alt="alertmanager.png" /></p>

<h2 id="添加-kubecontrollermanager-kubescheduler监控">添加 kubeControllerManager kubeScheduler监控</h2>
<blockquote>
  <p>在https://prometheus.saynaihe.com/targets中可以看到， kubeControllerManager kubeScheduler没有能正常监控。
<img src="/assets/images/monitoring/targets.png" alt="targets.png" /></p>
</blockquote>

<p>可参照https://www.qikqiak.com/post/first-use-prometheus-operator/ 阳明大佬的文档：</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-kubeControllerManagerService.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: kube-controller-manager
  labels:
    k8s-app: kube-controller-manager
spec:
  selector:
    component: kube-controller-manager
  ports:
  - name: http-metrics
    port: 10252
    targetPort: 10252
    protocol: TCP
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> prometheus-kubeControllerManagerService.yaml
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-kubeSchedulerService.yaml

apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: kube-scheduler
  labels:
    k8s-app: kube-scheduler
spec:
  selector:
    component: kube-scheduler
  ports:
  - name: http-metrics
    port: 10251
    targetPort: 10251
    protocol: TCP
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> prometheus-kubeSchedulerService.yaml
</code></pre></div></div>
<p><img src="/assets/images/monitoring/ready.png" alt="ready.png" /></p>
<h2 id="监控集群etcd服务">监控集群etcd服务</h2>
<blockquote>
  <p>kubernetes 安装etcd一般常用的是两种 外部搭建etcd和 容器化运行etc两种的方式都写了下。也特别说下既然都用了kubernetes了 都上了容器了 没有必要去外部搭建etd集群。尤其是后期集群升级，etcd的版本 各种的 会有些恶心，安装kubernetes集群还是安装官方的指导的安装比较好，个人觉得很多教程让二进制安装和kubeadm安装还外挂etcd集群的方式很爽反感。除非有良好系统的基础不建议那么的玩了。</p>
</blockquote>

<h3 id="kubadm安装集成etcd方式下操作">kubadm安装集成etcd方式下操作：</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nt">-n</span> monitoring create secret generic etcd-certs <span class="nt">--from-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/healthcheck-client.crt <span class="nt">--from-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/healthcheck-client.key <span class="nt">--from-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-serviceMonitorEtcd.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: etcd-k8s
  namespace: monitoring
  labels:
    k8s-app: etcd-k8s
spec:
  jobLabel: k8s-app
  endpoints:
  - port: port
    interval: 30s
    scheme: https
    tlsConfig:
      caFile: /etc/prometheus/secrets/etcd-certs/ca.crt
      certFile: /etc/prometheus/secrets/etcd-certs/healthcheck-client.crt
      keyFile: /etc/prometheus/secrets/etcd-certs/healthcheck-client.key
      insecureSkipVerify: true
  selector:
    matchLabels:
      k8s-app: etcd
  namespaceSelector:
    matchNames:
    - kube-system
</span><span class="no"> EOF

</span>kubectl apply <span class="nt">-f</span> prometheus-serviceMonitorEtcd.yaml
</code></pre></div></div>
<h3 id="kubadm安装挂载外部安装etcd方式下操作">kubadm安装挂载外部安装etcd方式下操作：</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nt">-n</span> monitoring create secret generic etcd-certs <span class="nt">--from-file</span><span class="o">=</span>/etc/etcd/ssl/ca.pem <span class="nt">--from-file</span><span class="o">=</span>/etc/etcd/ssl/server.pem <span class="nt">--from-file</span><span class="o">=</span>/etc/etcd/ssl/server-key.pem

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-serviceMonitorEtcd.yaml
apiVersion: v1
kind: Service
metadata:
  name: etcd-k8s
  namespace: kube-system
  labels:
    k8s-app: etcd
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: api
    port: 2379
    protocol: TCP
---
apiVersion: v1
kind: Endpoints
metadata:
  name: etcd-k8s
  namespace: kube-system
  labels:
    k8s-app: etcd
subsets:
- addresses:
  - ip: 192.168.0.195
    nodeName: etcd1
  - ip: 192.168.0.197
    nodeName: etcd2
  - ip: 192.168.0.198
    nodeName: etcd3
  ports:
  - name: api
    port: 2379
    protocol: TCP
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: etcd-k8s
  namespace: monitoring
  labels:
    k8s-app: etcd-k8s
spec:
  jobLabel: k8s-app
  endpoints:
  - port: api
    interval: 30s
    scheme: https
    tlsConfig:
      caFile: /etc/prometheus/secrets/etcd-certs/ca.pem
      certFile: /etc/prometheus/secrets/etcd-certs/server.pem
      keyFile: /etc/prometheus/secrets/etcd-certs/server-key.pem
      #use insecureSkipVerify only if you cannot use a Subject Alternative Name
      insecureSkipVerify: true 
  selector:
    matchLabels:
      k8s-app: etcd
  namespaceSelector:
    matchNames:
    - kube-system
</span><span class="no"> EOF
</span>kubectl apply <span class="nt">-f</span> prometheus-serviceMonitorEtcd.yaml
</code></pre></div></div>
<p><img src="/assets/images/monitoring/etcd1.png" alt="etcd1.png" /></p>

<h2 id="开启服务自动发现配置可持续存储修改prometheus-storage-retention参数设置数据保留时间">开启服务自动发现，配置可持续存储，修改prometheus Storage Retention参数设置数据保留时间</h2>
<blockquote>
  <p>参照https://www.qikqiak.com/post/prometheus-operator-advance/,自动发现集群中的 Service，就需要我们在 Service 的annotation区域添加prometheus.io/scrape=true的声明，然后通过这个文件创建一个对应的 Secret 对象。由于配置可持续存储和修改retention参数都在同一个配置文件就都写在一起了</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-additional.yaml

- job_name: 'kubernetes-service-endpoints'
  kubernetes_sd_configs:
  - role: endpoints
  relabel_configs:
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
    action: replace
    target_label: __scheme__
    regex: (https?)
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
  - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
    action: replace
    target_label: __address__
    regex: ([^:]+)(?::</span><span class="se">\d</span><span class="sh">+)?;(</span><span class="se">\d</span><span class="sh">+)
    replacement: </span><span class="nv">$1</span><span class="sh">:</span><span class="nv">$2</span><span class="sh">
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: kubernetes_name
</span><span class="no">EOF
</span><span class="nv">$ </span>kubectl create secret generic additional-configs <span class="nt">--from-file</span><span class="o">=</span>prometheus-additional.yaml <span class="nt">-n</span> monitoring
secret <span class="s2">"additional-configs"</span> created
<span class="c">#修改crd文件，</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-prometheus.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    prometheus: k8s
  name: k8s
  namespace: monitoring
spec:
  alerting:
    alertmanagers:
    - name: alertmanager-main
      namespace: monitoring
      port: web
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: rook-ceph-block
        resources:
          requests:
            storage: 20Gi
  baseImage: quay.io/prometheus/prometheus
  nodeSelector:
    kubernetes.io/os: linux
  podMonitorSelector: {}
  replicas: 2
  resources:
    requests:
      memory: 400Mi
  ruleSelector:
    matchLabels:
      prometheus: k8s
      role: alert-rules
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  additionalScrapeConfigs:
    name: additional-configs
    key: prometheus-additional.yaml
  serviceAccountName: prometheus-k8s
  retention: 15d
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector: {}
  version: v2.11.0
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> prometheus-prometheus.yaml
</code></pre></div></div>
<p><img src="/assets/images/monitoring/prometheus-prometheus.png" alt="prometheus-prometheus.png" /></p>
<h4 id="由于rabc权限问题prometheus-dashboard-的配置页面下面我们可以看到已经有了对应的的配置信息了但是我们切换到-targets-页面下面却并没有发现对应的监控任务">由于RABC权限问题，Prometheus Dashboard 的配置页面下面我们可以看到已经有了对应的的配置信息了，但是我们切换到 targets 页面下面却并没有发现对应的监控任务</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; prometheus-clusterRole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-k8s
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  - services
  - endpoints
  - pods
  - nodes/proxy
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  - nodes/metrics
  verbs:
  - get
- nonResourceURLs:
  - /metrics
  verbs:
  - get
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span>  rometheus-clusterRole.yaml
</code></pre></div></div>
<p><img src="/assets/images/monitoring/find-service.png" alt="find-service.png" /></p>

<h2 id="grafana添加监控模板持久化">grafana添加监控模板，持久化</h2>
<h3 id="持久化">持久化</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  grafana-pv.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana
  namespace: monitoring
spec:
  storageClassName: rook-ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> grafana-pv.yaml
修改grafana-deployment.yaml,如下图：
</code></pre></div></div>
<p><img src="/assets/images/monitoring/grafana-dev1.png" alt="grafana-dev1.png" />
<img src="/assets/images/monitoring/grafana-dev2.png" alt="grafana-dev2.png" /></p>

<blockquote>
  <p>kubectl apply -f grafana-deployment.yaml</p>
</blockquote>

<h3 id="grafana添加模板只添加了treafik2-和etcd模板">grafana添加模板，只添加了treafik2 和etcd模板</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>登录https://monitoring.saynaihe.com/dashboards  import模板号10906  3070.
打开dashboard，有的模板会出现Panel plugin not found: grafana-piechart-panel 。
解决方法：重新构建grafana镜像，/usr/share/grafana/bin/grafana-cli plugins <span class="nb">install </span>grafana-piechart-panel安装缺失插件
</code></pre></div></div>
<p><img src="/assets/images/monitoring/no-panel.png" alt="no-panel.png" />
<img src="/assets/images/monitoring/api.png" alt="api.png" />
<img src="/assets/images/monitoring/treafik.png" alt="treafik.png" />
<img src="/assets/images/monitoring/etcd-prometheus.png" alt="etcd-prometheus.png" /></p>

<h2 id="微信报警">微信报警</h2>
<blockquote>
  <p>将对应参数修改为自己微信企业号相对应参数</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; alertmanager.yaml 
    global:
      resolve_timeout: 2m
      wechat_api_url: 'https://qyapi.weixin.qq.com/cgi-bin/'
    route:
      group_by: ['alert']
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 1h
      receiver: wechat
    receivers:
    - name: 'wechat'
      wechat_configs:
      - api_secret: 'xxxx'
        send_resolved: true
        to_user: '@all'
        to_party: 'xxx'
        agent_id: 'xxx'
        corp_id: 'xxxx'
    templates:
      - '/etc/config/alert/wechat.tmpl'
    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'dev', 'instance']
</span><span class="no">EOF
</span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; wechat.tpl

☸ Alerts Firing ✖️ ‼️ :

☎️ 触发警报 ☔ ☠️ : 
☞名称空间: 
☞主机: 
☞job: 
-&gt;涉及容器名称: 
-&gt;Pod名称: 
告警级别: 
告警详情: 
触发时间⏱: 
警报链接: 
✍️ 备注详情❄️: 
--------------------&gt;END&lt;--------------------
☸ Alerts Resolved ✔️:

☎️ 触发警报 ☫ : 
♥️ 名称空间 ✝️ : 
♥️ -&gt;涉及容器名称: 
♥️ -&gt;Pod名称☸: 
♥️ 告警级别: 
♥️ 告警详情: 
♥️ 触发时间 ⏱ : 
♥️ 恢复时间 ⏲ : 
♥️ 备注详情: 
--------------------&gt;END&lt;--------------------
</span><span class="no">EOF
</span></code></pre></div></div>
<p><img src="/assets/images/monitoring/tpl.png" alt="tpl.png" />
<img src="/assets/images/monitoring/alertmanager1.png" alt="alertmanager.png" /></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete secret alertmanager-main <span class="nt">-n</span> monitoring
kubectl create secret generic alertmanager-main <span class="nt">--from-file</span><span class="o">=</span>alertmanager.yaml <span class="nt">--from-file</span><span class="o">=</span>wechat.tmpl <span class="nt">-n</span> monitoring
wechat.tpl模板可以根据自己需求自己定制，我这里就找了个网上的例子,格式不太会玩，貌似看不到，如下图
</code></pre></div></div>
<p><img src="/assets/images/monitoring/wechat.png" alt="wechat.png" /></p>

<blockquote>
  <p>基本完成。具体的修改可参考个人实际。</p>
</blockquote>

                </div>
                <div class="read-all">
                    <a  href="/2019/11/05/k8s-install-prometheus-operator/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/10/29/k8s-helm-install-hrbor/">2019-10-28-k8s-helm-install-harbor</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-10-29
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>&nbsp;
    
        <a href="/tag/#helm" title="Tag: helm" rel="tag">helm</a>&nbsp;
    
        <a href="/tag/#harbor" title="Tag: harbor" rel="tag">harbor</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#安装harbor" id="markdown-toc-安装harbor">安装harbor</a></li>
  <li><a href="#helm安装-harbor" id="markdown-toc-helm安装-harbor">helm安装 harbor</a></li>
  <li><a href="#treafik-代理harbor" id="markdown-toc-treafik-代理harbor">treafik 代理harbor</a></li>
  <li><a href="#web登录harbor" id="markdown-toc-web登录harbor">web登录harbor</a></li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：记录各种常见问题</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="安装harbor">安装harbor</h1>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 下载harbor仓库</span>
git clone https://github.com/goharbor/harbor-helm
注：偶尔会下载了 部署不成功，如有此状况尽量选择稳定分支。
<span class="c">#修改配置文件values.yaml</span>
代理使用了treafik,对外暴露模式没有使用loadBalancer和nodePort,选择了clusterIP，然后使用treafik代理，集群中安装了rook-ceph.存储storageClass: <span class="s2">"rook-ceph-block"</span>配置文件就修改了这两个配置。
</code></pre></div></div>
<p><img src="/assets/images/harbor/clusterIP.png" alt="clusterIP.png" />
<img src="/assets/images/harbor/storageClass.png" alt="storageClass.png" /></p>

<h1 id="helm安装-harbor">helm安装 harbor</h1>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm <span class="nb">install</span> <span class="nt">--name</span> harbor <span class="nt">-f</span> values.yaml <span class="nb">.</span> <span class="nt">--namespace</span> kube-ops
<span class="c"># 等待pod running</span>
kubectl get pods <span class="nt">-n</span> kube-ops <span class="nt">-w</span>  
如果pod一直pending 基本是pv,pvc的问题 查看下自己的storageclass ,pv,pvc配置
</code></pre></div></div>

<p><img src="/assets/images/harbor/svc.png" alt="svc.png" /></p>

<h1 id="treafik-代理harbor">treafik 代理harbor</h1>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kube-ops下创建http证书<span class="o">(</span>ssl证书目录下执行<span class="o">)</span>
kubectl create secret tls all-saynaihe-com <span class="nt">--key</span><span class="o">=</span>2_sainaihe.com.key <span class="nt">--cert</span><span class="o">=</span>1_saynaihe.com_bundle.crt <span class="nt">-n</span> kube-ops

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; harbor.saynaihe.com.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-https
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/`)
      kind: Rule
      services:
        - name: harbor-harbor-portal
          port: 80
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-api
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/api`)
      kind: Rule
      services:
        - name: harbor-harbor-core
          port: 80
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-service
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/service`)
      kind: Rule
      services:
        - name: harbor-harbor-core
          port: 80
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-v2
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/v2`)
      kind: Rule
      services:
        - name: harbor-harbor-core
          port: 80
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-chartrepo
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/chartrepo`)
      kind: Rule
      services:
        - name: harbor-harbor-core
          port: 80
---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  namespace: kube-ops
  name: harbor-c
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-saynaihe-com
  routes:
    - match: Host(`harbor.saynaihe.com`) &amp;&amp; PathPrefix(`/c`)
      kind: Rule
      services:
        - name: harbor-harbor-core
          port: 80
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> harbor.saynaihe.com.yaml
登录https://traefik.lsaynaihe.com/dashboard/#/http/routers 查看,如下图：

</code></pre></div></div>

<p><img src="/assets/images/harbor/harbor.png" alt="harbor.png" /></p>

<h1 id="web登录harbor">web登录harbor</h1>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>注：密码为配置文件中默认Harbor12345，在安装前可自定义修改，我选择了登录后自主修改：
OK安装完成，harbor还在摸索中，最喜欢的一个功能是同步其他仓库非常方便：
</code></pre></div></div>
<p><img src="/assets/images/harbor/harbor2.png" alt="harbor2.png" /></p>

<p><img src="/assets/images/harbor/harbor3.png" alt="harbor3.png" /></p>

<p><img src="/assets/images/harbor/harbor4.png" alt="harbor4.png" /></p>

                </div>
                <div class="read-all">
                    <a  href="/2019/10/29/k8s-helm-install-hrbor/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/10/28/k8s-helm-install/">2019-10-28-k8s-helm-install</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-10-28
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>&nbsp;
    
        <a href="/tag/#helm" title="Tag: helm" rel="tag">helm</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#安装helm2" id="markdown-toc-安装helm2">安装Helm2</a></li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：记录各种常见问题</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="安装helm2">安装Helm2</h1>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm 现在大版本有2和3两个版本，个人安装了helm2版本的1.15.1
<span class="nv">version</span><span class="o">=</span>v2.15.1
wget https://get.helm.sh/helm-<span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="nt">-linux-amd64</span>.tar.gz
<span class="nb">tar</span> <span class="nt">-zxvf</span> helm-<span class="k">*</span><span class="nt">-linux-amd64</span>.tar.gz
<span class="nb">cp </span>linux-amd64/helm /usr/local/bin/helm
<span class="c">#安装tiller</span>
helm init <span class="nt">--tiller-image</span><span class="o">=</span>gcr.azk8s.cn/kubernetes-helm/tiller:<span class="k">${</span><span class="nv">version</span><span class="k">}</span>
<span class="c">#查看helm版本</span>
helm version <span class="nt">--short</span>
Client: v2.15.1+gcf1de4f
Server: v2.15.1+gcf1de4f
但是kubernetes 1.16.2安装貌似会有权限问题的，执行以下命令：

kubectl <span class="nt">-n</span> kube-system create serviceaccount tiller
kubectl create clusterrolebinding tiller <span class="nt">--clusterrole</span> cluster-admin <span class="nt">--serviceaccount</span><span class="o">=</span>kube-system:tiller
helm init <span class="nt">--tiller-image</span><span class="o">=</span>gcr.azk8s.cn/kubernetes-helm/tiller:<span class="k">${</span><span class="nv">version</span><span class="k">}</span> <span class="nt">--service-account</span> tiller <span class="nt">--upgrade</span>
<span class="o">[</span>root@k8s-master-03 ~]# kubectl <span class="nt">-n</span> kube-system get all | <span class="nb">grep </span>tiller
pod/tiller-deploy-76858c97cd-sgmf6          1/1     Running   1          2d6h
service/tiller-deploy             ClusterIP   10.31.70.242    &lt;none&gt;        44134/TCP                          2d6h
deployment.apps/tiller-deploy   1/1     1            1           2d6h
replicaset.apps/tiller-deploy-76858c97cd   1         1         1       2d6h

</code></pre></div></div>

                </div>
                <div class="read-all">
                    <a  href="/2019/10/28/k8s-helm-install/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/10/21/k8s-question/">kuberntes1.16  question</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-10-21
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>&nbsp;
    
        <a href="/tag/#qustion" title="Tag: qustion" rel="tag">qustion</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#1网桥配置问题sd_journal_get_cursor-failed-cannot-assign-requested-address--v8240-34el7" id="markdown-toc-1网桥配置问题sd_journal_get_cursor-failed-cannot-assign-requested-address--v8240-34el7">1.网桥配置问题：sd_journal_get_cursor() failed: ‘Cannot assign requested address’  [v8.24.0-34.el7]</a></li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：记录各种常见问题</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="1网桥配置问题sd_journal_get_cursor-failed-cannot-assign-requested-address--v8240-34el7">1.网桥配置问题：sd_journal_get_cursor() failed: ‘Cannot assign requested address’  [v8.24.0-34.el7]</h1>
<p><img src="/assets/images/qustion/bridge.png" alt="bridge.png" /></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubernetes 集群中有内部同一namespace下通信用的直接连service的方式有一service下pod访问另外一service无法访问。但是访问其他同一命名空间下都是没有问题的，kubectl get pod <span class="nt">-o</span> wide  看到此pod位于node-07.node-07节点执行journalctl  看日志中有sd_journal_get_cursor<span class="o">()</span> failed: <span class="s1">'Cannot assign requested address'</span>  <span class="o">[</span>v8.24.0-34.el7]，百度了下https://blog.csdn.net/wkb342814892/article/details/79543984应该是没有开启网桥转发：
modprobe br_netfilter
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
</span><span class="no">EOF
</span>sysctl <span class="nt">-p</span> /etc/sysctl.d/k8s.conf
<span class="nb">ls</span> /proc/sys/net/bridge
</code></pre></div></div>
<p>OK问题解决</p>

                </div>
                <div class="read-all">
                    <a  href="/2019/10/21/k8s-question/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/10/21/k8s-efk/">kuberntes1.16安装efk</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-10-21
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>&nbsp;
    
        <a href="/tag/#elastic" title="Tag: elastic" rel="tag">elastic</a>&nbsp;
    
        <a href="/tag/#fluent-bit" title="Tag: fluent-bit" rel="tag">fluent-bit</a>&nbsp;
    
        <a href="/tag/#Elasticsearch" title="Tag: Elasticsearch" rel="tag">Elasticsearch</a>&nbsp;
    
        <a href="/tag/#Operator" title="Tag: Operator" rel="tag">Operator</a>&nbsp;
    
        <a href="/tag/#Elastic" title="Tag: Elastic" rel="tag">Elastic</a>&nbsp;
    
        <a href="/tag/#Cloud" title="Tag: Cloud" rel="tag">Cloud</a>&nbsp;
    
        <a href="/tag/#on" title="Tag: on" rel="tag">on</a>&nbsp;
    
        <a href="/tag/#Kubernetes" title="Tag: Kubernetes" rel="tag">Kubernetes</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#关于elastic-cloud-on-kubernetes" id="markdown-toc-关于elastic-cloud-on-kubernetes">关于Elastic Cloud on Kubernetes</a></li>
  <li><a href="#安装elastic-cloud-on-kubernetes" id="markdown-toc-安装elastic-cloud-on-kubernetes">安装Elastic Cloud on Kubernetes</a></li>
  <li><a href="#安装elasticsearch-on-cluster" id="markdown-toc-安装elasticsearch-on-cluster">安装elasticsearch on cluster</a></li>
  <li><a href="#安装kibana-on-cluaster" id="markdown-toc-安装kibana-on-cluaster">安装kibana on cluaster</a></li>
  <li><a href="#kibana-traefik对外暴露" id="markdown-toc-kibana-traefik对外暴露">kibana traefik对外暴露</a></li>
  <li><a href="#接下来fluent-bit-安装" id="markdown-toc-接下来fluent-bit-安装">接下来fluent-bit 安装</a></li>
  <li><a href="#登录kibana-进行相关配置" id="markdown-toc-登录kibana-进行相关配置">登录kibana 进行相关配置</a></li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<p>注：  文章配置文件示例都是拿阳明大佬博客https://www.qikqiak.com/post/elastic-cloud-on-k8s/ 还有elastic官方文档，阳明大佬文档是旧的新版本有所改变尽量参考官方文档，fluent-bit也有必要看下官方文档 —</p>

<p>集群配置：
初始集群环境kubeadm 1.16.1</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ip</th>
      <th style="text-align: center">自定义域名</th>
      <th style="text-align: center">主机名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">192.168.3.8</td>
      <td style="text-align: center">master.k8s.io</td>
      <td style="text-align: center">k8s-vip</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.10</td>
      <td style="text-align: center">master01.k8s.io</td>
      <td style="text-align: center">k8s-master-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.5</td>
      <td style="text-align: center">master02.k8s.io</td>
      <td style="text-align: center">k8s-master-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.12</td>
      <td style="text-align: center">master03.k8s.io</td>
      <td style="text-align: center">k8s-master-03</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.6</td>
      <td style="text-align: center">node01.k8s.io</td>
      <td style="text-align: center">k8s-node-01</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.2</td>
      <td style="text-align: center">node02.k8s.io</td>
      <td style="text-align: center">k8s-node-02</td>
    </tr>
    <tr>
      <td style="text-align: center">192.168.3.4</td>
      <td style="text-align: center">node03.k8s.io</td>
      <td style="text-align: center">k8s-node-03</td>
    </tr>
  </tbody>
</table>

<h1 id="关于elastic-cloud-on-kubernetes">关于Elastic Cloud on Kubernetes</h1>

<p>Elastic Cloud on Kubernetes(ECK)是一个 Elasticsearch Operator，elastic推出的一个便于部署管理的项目，而且内部集成了核心安全功能（TLS 加密、基于角色的访问控制，以及文件和原生身份验证）免费提供。</p>

<h1 id="安装elastic-cloud-on-kubernetes">安装Elastic Cloud on Kubernetes</h1>

<p>当前最新版本为1.0，参考：https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-quickstart.html。</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> https://download.elastic.co/downloads/eck/1.0.0-beta1/all-in-one.yaml
kubectl get pods <span class="nt">-n</span> elastic-system
kubectl <span class="nt">-n</span> elastic-system logs <span class="nt">-f</span> statefulset.apps/elastic-operator
</code></pre></div></div>
<p><img src="/assets/images/efk/eck1.png" alt="eck1.png" /></p>

<h1 id="安装elasticsearch-on-cluster">安装elasticsearch on cluster</h1>

<p>官方示例  0.8 示例中apiversion还是elasticsearch.k8s.elastic.co/v1alpha1，1.0更新为elasticsearch.k8s.elastic.co/v1beta1。所以最好能看下最新的官方文档。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: elasticsearch.k8s.elastic.co/v1beta1
kind: Elasticsearch
metadata:
  name: elastic
  namespace: elastic-system
spec:
  version: 7.4.0
  nodeSets:
  - name: default
    count: 3
    config:
      node.master: true
      node.data: true
      node.ingest: true
      node.store.allow_mmap: false
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 5Gi
        storageClassName: rook-ceph-block
</span><span class="no">EOF
</span>注：采用默认官方的了,个人安装了rook ceph 就用了rook-ceph-block，由于是测试storage就设置为5G。另外如果指定运行node节点可以设置lable根据个人需求设置
</code></pre></div></div>
<p><img src="/assets/images/efk/storageclass.png" alt="storageclass.png" />
<img src="/assets/images/efk/elastic1.png" alt="elastic1.png" /></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods <span class="nt">-n</span> elastic-system <span class="nt">-o</span> wide
kubectl <span class="nt">-n</span> elastic-system get pods <span class="nt">--selector</span><span class="o">=</span><span class="s1">'elasticsearch.k8s.elastic.co/cluster-name=elastic'</span>（官方文档的查看方式，看个人使用习惯了呢）

kubectl get elasticsearch <span class="nt">-n</span> elastic-system

kubectl get service <span class="nt">-n</span> elastic-system

获取elastic链接用户密码，默认用户为elastic
kubectl <span class="nt">-n</span> elastic-system get secret elastic-es-elastic-user <span class="nt">-o</span><span class="o">=</span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.data.elastic}'</span> | <span class="nb">base64</span> <span class="nt">--decode</span><span class="p">;</span> <span class="nb">echo</span>

</code></pre></div></div>
<p><img src="/assets/images/efk/elastic2.png" alt="elastic2.png" />
<img src="/assets/images/efk/svc.png" alt="svc.png" />
<img src="/assets/images/efk/secret.png" alt="secret.png" /></p>

<h1 id="安装kibana-on-cluaster">安装kibana on cluaster</h1>
<p>依然官方示例</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: kibana.k8s.elastic.co/v1beta1
kind: Kibana
metadata:
  name: kibana
  namespace: elastic-system
spec:
  version: 7.4.0
  count: 1
  elasticsearchRef:
    name: elastic
  http:
    tls:
      selfSignedCertificate:
        disabled: true
</span><span class="no">EOF
</span>注意：属性spec.elasticsearchRef.name的值为上面我们创建的 Elasticsearch 对象的 name：elastic。直接添加这个资源对象即可，配置文件下方关于http的配置参照https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-kibana.html#k8s-kibana-http-configuration disable tls为了方便外部traefik负载。

kubectl get kibana <span class="nt">-n</span> elastic-system

kubectl <span class="nt">-n</span> elastic-system get pod <span class="nt">--selector</span><span class="o">=</span><span class="s1">'kibana.k8s.elastic.co/name=kibana'</span>


kuberctl get svc <span class="nt">-n</span> elastic-system

</code></pre></div></div>
<p><img src="/assets/images/efk/kibana.png" alt="kibana.png" /></p>

<h1 id="kibana-traefik对外暴露">kibana traefik对外暴露</h1>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  ingress.yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: kibana-kb-http
  namespace: elastic-system
spec:
  entryPoints:
    - websecure
  tls:
    secretName: all-sainaihe-com
  routes:
    - match: Host(`kibana123.saynaihe.com`)
      kind: Rule
      services:
        - name: kibana-kb-http
          port: 5601
</span><span class="no">EOF
</span>kubectl apply <span class="nt">-f</span> ingress.yaml
kubectl get ingressroute <span class="nt">-n</span> elastic-system
</code></pre></div></div>
<p><img src="/assets/images/efk/ingress.png" alt="ingress.png" />
<img src="/assets/images/efk/ingess1.png" alt="ingess1.png" />
<img src="/assets/images/efk/welcome.png" alt="welcome.png" /></p>
<h1 id="接下来fluent-bit-安装">接下来fluent-bit 安装</h1>
<p>kubernetes 采集日志比较常用的有很多比如elasitc自己的logstash  filebeat ，
还有fluent，另外fluent还有专门针对kubernetes的fluent-bit，各种优劣 可以找文档对比，最终我选择了fluent-bit.先按照https://github.com/fluent/fluent-bit-kubernetes-logging。 README.md修改下配置文件。</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/fluent/fluent-bit-kubernetes-logging
<span class="nb">cd</span> /fluent/fluent-bit-kubernetes-logging
注： 修改下配置文件将默认的namespace修改下与eck在同一命名空间下
修改后文件如下：
<span class="nt">------</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  fluent-bit-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit
  namespace: elastic-system
</span><span class="no">EOF
</span><span class="nt">------</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  fluent-bit-role.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: fluent-bit-read
  namespace: elastic-system
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  verbs: ["get", "list", "watch"]
</span><span class="no">EOF
</span><span class="nt">------</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt;  fluent-bit-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit-read
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit-read
subjects:
- kind: ServiceAccount
  name: fluent-bit
  namespace: elastic-system
</span><span class="no">EOF
</span><span class="nt">------</span>

kubectl apply <span class="nt">-f</span> fluent-bit-service-account.yaml
kubectl apply <span class="nt">-f</span> fluent-bit-role.yaml
kubectl apply <span class="nt">-f</span> fluent-bit-role-binding.yaml
<span class="nt">------</span>
<span class="nb">cd </span>output/elasticsearch/
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; fluent-bit-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: elastic-system
  labels:
    k8s-app: fluent-bit
data:
  # Configuration files: server, input, filters and output
  # ======================================================
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE input-kubernetes.conf
    @INCLUDE filter-kubernetes.conf
    @INCLUDE output-elasticsearch.conf

  input-kubernetes.conf: |
    [INPUT]
        Name              tail
        Tag               kube.*
        Path              /var/log/containers/*.log
        Parser            docker
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     5MB
        Skip_Long_Lines   On
        Refresh_Interval  10

  filter-kubernetes.conf: |
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix     kube.var.log.containers.
        Merge_Log           On
        Merge_Log_Key       log_processed
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off

  output-elasticsearch.conf: |
    [OUTPUT]
        Name            es
        Match           *
        Host            elastic-es-http
        Port            9200
        HTTP_User       elastic
        HTTP_Passwd     *********
        tls   on
        tls.verify   off
        Logstash_Format On
        Replace_Dots    On
        Retry_Limit     False

  parsers.conf: |
    [PARSER]
        Name   apache
        Format regex
        Regex  ^(?&lt;host&gt;[^ ]*) [^ ]* (?&lt;user&gt;[^ ]*) </span><span class="se">\[</span><span class="sh">(?&lt;time&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh"> "(?&lt;method&gt;</span><span class="se">\S</span><span class="sh">+)(?: +(?&lt;path&gt;[^</span><span class="se">\"</span><span class="sh">]*?)(?: +</span><span class="se">\S</span><span class="sh">*)?)?" (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: "(?&lt;referer&gt;[^</span><span class="se">\"</span><span class="sh">]*)" "(?&lt;agent&gt;[^</span><span class="se">\"</span><span class="sh">]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z

    [PARSER]
        Name   apache2
        Format regex
        Regex  ^(?&lt;host&gt;[^ ]*) [^ ]* (?&lt;user&gt;[^ ]*) </span><span class="se">\[</span><span class="sh">(?&lt;time&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh"> "(?&lt;method&gt;</span><span class="se">\S</span><span class="sh">+)(?: +(?&lt;path&gt;[^ ]*) +</span><span class="se">\S</span><span class="sh">*)?" (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: "(?&lt;referer&gt;[^</span><span class="se">\"</span><span class="sh">]*)" "(?&lt;agent&gt;[^</span><span class="se">\"</span><span class="sh">]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z

    [PARSER]
        Name   apache_error
        Format regex
        Regex  ^</span><span class="se">\[</span><span class="sh">[^ ]* (?&lt;time&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh"> </span><span class="se">\[</span><span class="sh">(?&lt;level&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh">(?: </span><span class="se">\[</span><span class="sh">pid (?&lt;pid&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh">)?( </span><span class="se">\[</span><span class="sh">client (?&lt;client&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh">)? (?&lt;message&gt;.*)$

    [PARSER]
        Name   nginx
        Format regex
        Regex ^(?&lt;remote&gt;[^ ]*) (?&lt;host&gt;[^ ]*) (?&lt;user&gt;[^ ]*) </span><span class="se">\[</span><span class="sh">(?&lt;time&gt;[^</span><span class="se">\]</span><span class="sh">]*)</span><span class="se">\]</span><span class="sh"> "(?&lt;method&gt;</span><span class="se">\S</span><span class="sh">+)(?: +(?&lt;path&gt;[^</span><span class="se">\"</span><span class="sh">]*?)(?: +</span><span class="se">\S</span><span class="sh">*)?)?" (?&lt;code&gt;[^ ]*) (?&lt;size&gt;[^ ]*)(?: "(?&lt;referer&gt;[^</span><span class="se">\"</span><span class="sh">]*)" "(?&lt;agent&gt;[^</span><span class="se">\"</span><span class="sh">]*)")?$
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z

    [PARSER]
        Name   json
        Format json
        Time_Key time
        Time_Format %d/%b/%Y:%H:%M:%S %z

    [PARSER]
        Name        docker
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On

    [PARSER]
        Name        syslog
        Format      regex
        Regex       ^</span><span class="se">\&lt;</span><span class="sh">(?&lt;pri&gt;[0-9]+)</span><span class="se">\&gt;</span><span class="sh">(?&lt;time&gt;[^ ]* {1,2}[^ ]* [^ ]*) (?&lt;host&gt;[^ ]*) (?&lt;ident&gt;[a-zA-Z0-9_</span><span class="se">\/\.\-</span><span class="sh">]*)(?:</span><span class="se">\[</span><span class="sh">(?&lt;pid&gt;[0-9]+)</span><span class="se">\]</span><span class="sh">)?(?:[^</span><span class="se">\:</span><span class="sh">]*</span><span class="se">\:</span><span class="sh">)? *(?&lt;message&gt;.*)$
        Time_Key    time
        Time_Format %b %d %H:%M:%S
</span><span class="no">EOF
</span><span class="nt">------</span>
注：基本还是默认的就修改了namespace 还有output-elasticsearch.conf中 Host  Port   HTTP_User  HTTP_Passwd  tls   tls.verify具体参考https://docs.fluentbit.io/manual/configuration 官方文档
<span class="nt">------</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; fluent-bit-ds.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: elastic-system
  labels:
    k8s-app: fluent-bit-logging
    version: v1
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: fluent-bit-logging
  template:
    metadata:
      labels:
        k8s-app: fluent-bit-logging
        version: v1
        kubernetes.io/cluster-service: "true"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "2020"
        prometheus.io/path: /api/v1/metrics/prometheus
    spec:
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:1.2.1
        imagePullPolicy: Always
        ports:
          - containerPort: 2020
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elastic-es-http"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
      terminationGracePeriodSeconds: 10
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-config
      serviceAccountName: fluent-bit
      tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - operator: "Exists"
        effect: "NoExecute"
      - operator: "Exists"
        effect: "NoSchedule"
</span><span class="no">EOF
</span><span class="nt">------</span>
注: 修改了下apiversion  1.16取消了extensions/v1beta1  更改为apps/v1
配置文件增加  selector: 相关配置。FLUENT_ELASTICSEARCH_HOST  FLUENT_ELASTICSEARCH_PORT  对应value输入
<span class="nt">------</span>
kubectl apply <span class="nt">-f</span> fluent-bit-configmap.yaml
kubectl apply <span class="nt">-f</span> fluent-bit-ds.yaml
kubectl get pods <span class="nt">-n</span> elastic-system

</code></pre></div></div>
<p><img src="/assets/images/efk/fluent-bit.png" alt="fluent-bit.png" /></p>
<h1 id="登录kibana-进行相关配置">登录kibana 进行相关配置</h1>

<p><img src="/assets/images/efk/kibana1.png" alt="kibana1.png" />
<img src="/assets/images/efk/kibana2.png" alt="kibana2.png" />
<img src="/assets/images/efk/kibana3.png" alt="kibana3.png" />
<img src="/assets/images/efk/kibana4.png" alt="kibana3.png" /></p>

<p>注：发现rook的日志单行了 后续将完善下各种日志的格式还有其他相关问题</p>

                </div>
                <div class="read-all">
                    <a  href="/2019/10/21/k8s-efk/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2019/10/17/k8s-traefik2/">traefik2 安装实现 http  https</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2019-10-17
                    </div>
                    <div class="label-card">
                        <i class="fa fa-user"></i>duiniwukenaihe
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#kubernetes" title="Category: kubernetes" rel="category">kubernetes</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#traefik2" title="Tag: traefik2" rel="tag">traefik2</a>&nbsp;
    
        <a href="/tag/#kubernetes" title="Tag: kubernetes" rel="tag">kubernetes</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <ul id="markdown-toc">
  <li><a href="#描述背景" id="markdown-toc-描述背景">描述背景：</a></li>
  <li><a href="#关于traefik" id="markdown-toc-关于traefik">关于Traefik</a></li>
</ul>

<h1 id="描述背景">描述背景：</h1>
<blockquote>
  <p>注：  文章配置文件示例都是拿阳明大佬的还有良哥转发的http://www.mydlq.club/article/41 超级小豆丁的文章中参考的。个人只是拿来整合测试了下整合，鸣谢各位大佬。</p>
</blockquote>

<blockquote>
  <p>开始使用腾讯云tke,slb对外映射方式 还需要对外开启Nodeport  然后slb对端口映射，个人觉得比较反人类，然后看到阳明 良哥两位大佬都发了traefik的方式就试用了一下。</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>集群配置：
初始集群环境kubeadm 1.16.1

|  ip           | 自定义域名         |    主机名 |
|  :----:       |     :----:        |   :----:  |
|192.168.3.8      |  master.k8s.io    |  k8s-vip  |
|192.168.3.10    |  master01.k8s.io  |  k8s-master-01|
|192.168.3.5   |  master02.k8s.io  |  k8s-master-02| 
|192.168.3.12   |  master03.k8s.io  |  k8s-master-03|
|192.168.3.6    |  node01.k8s.io    |  k8s-node-01|
|192.168.3.2    |  node02.k8s.io    |  k8s-node-02|
|192.168.3.4    |  node03.k8s.io    |  k8s-node-03|
k8s-node-01 k8s-node-02 k8s-node-03 绑定了腾讯云负载均衡应用负载均衡并对外暴露了80  443两个端口，开始443想放在https监听器哪里，但是这样一个sbl负载均衡只能绑定一个证书的，业务不太多，不想用多个slb，就将443端口监听放在了tcp/udp监听器这里，然后证书在kubernetes集群中创建绑定在traefik上。
</code></pre></div></div>
<h1 id="关于traefik">关于Traefik</h1>
<blockquote>
  <p>Traefik 2.0 官方文档：https://docs.traefik.io/v2.0/ 比较乱，中文的可参照阳明大佬的中文翻译https://www.qikqiak.com/traefik-book/</p>
</blockquote>

                </div>
                <div class="read-all">
                    <a  href="/2019/10/17/k8s-traefik2/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
        </ul>



        <!-- Pagination links -->
        <div class="pagination">
          
            <a href="/index.html" class="previous"><i class="fa fa-angle-double-left"></i></a>
            <a href="/" class="previous"><i class="fa fa-angle-left"></i></a>
          
          <span class="page_number ">2/3</span>
          
            <a href="/page3" class="next"><i class="fa fa-angle-right"></i></a>
            <a href="/page3" class="next"><i class="fa fa-angle-double-right"></i></a>
          
        </div>
    </div>
    <!-- <button class="anchor"><i class="fa fa-anchor"></i></button> -->
    <div class="right">
        <div class="wrap">
		    <div class="col-md-3 hidden-sm hidden-xs">
                <div class="side">
                    <div>
                        <i class="fa fa-search" aria-hidden="true"></i>
                        Search
                     </div>
                    <div id="site_search">
  <div class="has-feedback">
    <input type="text" id="search_box" class="form-control" placeholder="Search...">
    <span class="glyphicon glyphicon-search form-control-feedback"></span>
  </div>
</div>

<ul class="search-ul" id="search_results" recent></ul>

<style>
  .form-control {
      display: block;
      padding: 6px 12px;
      font-size: 14px;
      line-height: 1.42857143;
      color: #555;
      background-color: #fff;
      background-image: none;
      border: 1px solid #ccc;
      border-radius: 4px;
      -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075);
      box-shadow: inset 0 1px 1px rgba(0,0,0,.075);
      -webkit-transition: border-color ease-in-out .15s,-webkit-box-shadow ease-in-out .15s;
      -o-transition: border-color ease-in-out .15s,box-shadow ease-in-out .15s;
      transition: border-color ease-in-out .15s,box-shadow ease-in-out .15s;
  }
  .search-ul {
    list-style: none;
    margin: 10px;
    padding: 5px;
	font-size: 14px;
  }
  .search-ul>li {
    padding: 5px 0;
    border-bottom: 1px solid #ccc;
  }
  .search-ul>li:last-child {
    border: 0;
  }
  .ais-Highlight {
    color: #FF6666;
    font-style: normal;
    font-weight: bold;
    text-decoration: underline;
  }
</style>

<script src="http://localhost:4000/js/jekyll-search.min.js"></script>
<script type="text/javascript">
  SimpleJekyllSearch({
    searchInput: document.getElementById('search_box'),
    resultsContainer: document.getElementById('search_results'),
    json: '/search_data.json',
    searchResultTemplate: '<li><a href="{url}">{title}</a></li>',
    noResultsText: 'No results found',
    limit: 10,
    fuzzy: false,
	templateMiddleware: function(prop, value, template) {
		if (prop === 'title') {
			var v = document.getElementById('search_box').value;
			var i = value.toLowerCase().indexOf(v.toLowerCase());
			var s = value.slice(i, i + v.length);
            return value.replace(s,'<em class="ais-Highlight">' + s +'</em>')
        }
    }
  });
</script>
                </div>
            </div>
            <div class="side">
                <div>
                    <i class="fa fa-pencil-square-o" aria-hidden="true"></i>
                    Recent Posts
                </div>
                <ul class="content-ul" recent>
                    
                        <li><a href="/2020/09/11/hadoop-ha-hbase-hive-spark/">2020-09-11-hadoop-ha-hbase-hive-spark</a></li>
                    
                        <li><a href="/2020/07/31/kubernetes-csi-tencentcloud-cosfs/">2020-07-31-kubernetes集群使用腾讯云cos存储</a></li>
                    
                        <li><a href="/2020/07/27/kubernets-traefik/">2020-07-27-kubernets-traefik</a></li>
                    
                        <li><a href="/2020/07/23/kubernetes-question-etcd/">2020-07-23-qestion-etcd(error execution phase check-etcd)</a></li>
                    
                        <li><a href="/2020/07/23/kubernetes-csi-tencentcloud-cbs/">2020-07-23-kubernetes集群使用腾讯云cbs块存储</a></li>
                    
                        <li><a href="/2020/07/22/tencent-slb-kubeadm-ha/">2020-07-22-腾讯云-slb-kubeadm高可用集群搭建</a></li>
                    
                        <li><a href="/2019/12/27/traefik/">2019-12-27-traefik</a></li>
                    
                        <li><a href="/2019/12/05/eck-qustion/">2019-12-05-eck-qustion</a></li>
                    
                        <li><a href="/2019/12/03/k8s-jenkins-sonarqube/">2019-12-03-k8s-jenkins-sonarqube</a></li>
                    
                        <li><a href="/2019/11/29/k8s-helm-install-postgresql-sonarqube/">2019-11-29-k8s-helm-install-postgresql-sonarqube</a></li>
                    
                </ul>
            </div>

            <!-- Content -->
            <div class="side ">
                <div>
                    <i class="fa fa-th-list"></i>
                    Categories
                </div>
                <ul class="content-ul" cate>
                    
                    <li>
                        <a href="/category/#jekyll" class="categories-list-item" cate="jekyll">
                            <span class="name">
                                jekyll
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#kubernetes" class="categories-list-item" cate="kubernetes">
                            <span class="name">
                                kubernetes
                            </span>
                            <span class="badge">23</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#elastic-oparator" class="categories-list-item" cate="elastic-oparator">
                            <span class="name">
                                elastic-oparator
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#traefik" class="categories-list-item" cate="traefik">
                            <span class="name">
                                traefik
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#hadoop" class="categories-list-item" cate="hadoop">
                            <span class="name">
                                hadoop
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <div class="side">
                <div>
                    <i class="fa fa-tags"></i>
                    Tags
                </div>
                <div class="tags-cloud">
                    
                    
                    
                    

                    

                    
                      
                      
                      
                      
                      
                      <a href="/tag/#jekyll" style="font-size: 9pt; color: #999;">jekyll</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes" style="font-size: 18pt; color: #000;">kubernetes</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#rook" style="font-size: 9pt; color: #999;">rook</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#ceph" style="font-size: 9pt; color: #999;">ceph</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Operator" style="font-size: 10pt; color: #888;">Operator</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#gitlab" style="font-size: 9pt; color: #999;">gitlab</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#docker" style="font-size: 9pt; color: #999;">docker</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes扩容" style="font-size: 9pt; color: #999;">kubernetes扩容</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#elasticsearch" style="font-size: 9pt; color: #999;">elasticsearch</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes升级" style="font-size: 9pt; color: #999;">kubernetes升级</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#traefik2" style="font-size: 9pt; color: #999;">traefik2</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#elastic" style="font-size: 9pt; color: #999;">elastic</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#fluent-bit" style="font-size: 9pt; color: #999;">fluent-bit</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Elasticsearch" style="font-size: 9pt; color: #999;">Elasticsearch</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Elastic" style="font-size: 9pt; color: #999;">Elastic</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Cloud" style="font-size: 9pt; color: #999;">Cloud</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#on" style="font-size: 10pt; color: #888;">on</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Kubernetes" style="font-size: 9pt; color: #999;">Kubernetes</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#qustion" style="font-size: 9pt; color: #999;">qustion</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#helm" style="font-size: 10.5pt; color: #777;">helm</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#harbor" style="font-size: 9pt; color: #999;">harbor</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#prometheus-operator" style="font-size: 9pt; color: #999;">prometheus-operator</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes1.16" style="font-size: 10pt; color: #888;">kubernetes1.16</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#jenkins" style="font-size: 10.5pt; color: #777;">jenkins</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#question" style="font-size: 9pt; color: #999;">question</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#no" style="font-size: 9pt; color: #999;">no</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#space" style="font-size: 9pt; color: #999;">space</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#left" style="font-size: 9pt; color: #999;">left</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#device" style="font-size: 9pt; color: #999;">device</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes1.16.2" style="font-size: 9pt; color: #999;">kubernetes1.16.2</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kuberadm" style="font-size: 10pt; color: #888;">kuberadm</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#postgresql" style="font-size: 9pt; color: #999;">postgresql</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#sonarqube" style="font-size: 10pt; color: #888;">sonarqube</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#elastic-oparator" style="font-size: 9pt; color: #999;">elastic-oparator</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#ECK" style="font-size: 9pt; color: #999;">ECK</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#traefik" style="font-size: 10pt; color: #888;">traefik</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes1.18.6" style="font-size: 10.5pt; color: #777;">kubernetes1.18.6</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#高可用" style="font-size: 9pt; color: #999;">高可用</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#ha" style="font-size: 9pt; color: #999;">ha</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes-csi-tencentcloud" style="font-size: 10pt; color: #888;">kubernetes-csi-tencentcloud</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#kubernetes1.16.8" style="font-size: 10pt; color: #888;">kubernetes1.16.8</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#etcd" style="font-size: 10pt; color: #888;">etcd</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#check-etcd" style="font-size: 9pt; color: #999;">check-etcd</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#监控检查失败" style="font-size: 9pt; color: #999;">监控检查失败</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Ingress" style="font-size: 9pt; color: #999;">Ingress</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#controller" style="font-size: 9pt; color: #999;">controller</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#cosfs" style="font-size: 9pt; color: #999;">cosfs</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#hadoop" style="font-size: 9pt; color: #999;">hadoop</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#hbase" style="font-size: 9pt; color: #999;">hbase</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#hive" style="font-size: 9pt; color: #999;">hive</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#spark" style="font-size: 9pt; color: #999;">spark</a>
                    
                </div>
            </div>

            <!-- <div class="side">
                <div>
                    <i class="fa fa-external-link"></i>
                    Links
                </div>
                <ul  class="content-ul">

                </ul>
            </div> -->
        </div>
    </div>
</div>
<!-- <script src="/js/scroll.min.js " charset="utf-8"></script> -->
<!-- <script src="/js/pageContent.js " charset="utf-8"></script> -->


    <footer class="site-footer">


    <div class="wrapper">

        <p class="description">
             本站记录我成长之路的点点滴滴！ 
        </p>
        <p class="contact">
            Contact me at: 
            <a href="https://github.com/duiniwukenaihe" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:zhangpeng19871017@hotmail.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>  
            <a href="http://weibo.com/duiniwukenaihe" title="Weibo"><i class="fa fa-weibo" aria-hidden="true"></i></a>       
        </p>
        <p>
            本站总访问量<span id="busuanzi_value_site_pv"></span>次，本站访客数<span id="busuanzi_value_site_uv"></span>人次，本文总阅读量<span id="busuanzi_value_page_pv"></span>次
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
    <!-- <script src=" /js/scroll.min.js " charset="utf-8"></script> -->
  </body>

</html>
